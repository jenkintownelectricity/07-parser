from flask import Flask, render_template, request, jsonify
import os
import json
import sys
import PyPDF2
import re
from parsers.text_cleaner import clean_rtf_text, deduplicate_list
from parsers.assembly_parser import parse_assembly_letter
from parsers.arch_drawing_parser import parse_architectural_drawing
from parsers.spec_parser import SpecParser
from parsers.scope_parser import parse_scope
from parsers.large_drawing_set_parser import LargeDrawingSetParser, DrawingSetFilter

# Fix Windows console encoding for emoji support
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

app = Flask(__name__)
UPLOAD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static', 'uploads')
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def extract_text_from_pdf(filepath):
    """Extract text from PDF file with better error handling"""
    text = ""
    try:
        with open(filepath, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_pages = len(pdf_reader.pages)
            print(f"ðŸ“„ Extracting {total_pages} pages from: {os.path.basename(filepath)}")
            
            for i, page in enumerate(pdf_reader.pages, 1):
                page_text = page.extract_text()
                text += page_text + "\n"
                print(f"  âœ“ Page {i}/{total_pages} - {len(page_text)} chars")
            
            print(f"  ðŸ“Š Total extracted: {len(text)} characters")
    except Exception as e:
        print(f"âŒ Error extracting text from {filepath}: {str(e)}")
        return ""
    return text

def safe_jsonify(data):
    """Safely convert data to JSON-serializable format"""
    if isinstance(data, dict):
        return {k: safe_jsonify(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [safe_jsonify(item) for item in data]
    elif isinstance(data, (str, int, float, bool, type(None))):
        return data
    else:
        return str(data)

# ============================================================================
# DOCUMENT PARSERS
# ============================================================================

def parse_scope_of_work(text):
    """Parse Scope of Work document"""
    print("\n" + "="*60)
    print("ðŸ” PARSING SCOPE OF WORK")
    print("="*60)
    
    text = clean_rtf_text(text)
    
    # Extract materials
    materials = []
    material_patterns = [
        r'(?i)materials?:\s*([^\n]+)',
        r'(?i)product[s]?:\s*([^\n]+)',
    ]
    
    for pattern in material_patterns:
        matches = re.findall(pattern, text)
        materials.extend(matches)
    
    materials = deduplicate_list(materials)
    print(f"  âœ“ Found {len(materials)} materials")
    
    # Extract requirements
    requirements = []
    req_patterns = [
        r'(?i)requirement[s]?:\s*([^\n]+)',
        r'(?i)shall\s+([^\n]+)',
    ]
    
    for pattern in req_patterns:
        matches = re.findall(pattern, text)
        requirements.extend(matches)
    
    requirements = deduplicate_list(requirements[:10])
    print(f"  âœ“ Found {len(requirements)} requirements")
    
    # Create summary
    sentences = text.split('.')[:3]
    summary = '. '.join(sentences).strip()
    print(f"  âœ“ Generated summary ({len(summary)} chars)")
    
    result = {
        'summary': summary[:500] if summary else None,
        'materials': materials[:15] if materials else None,
        'requirements': requirements if requirements else None
    }
    
    print("="*60 + "\n")
    return result

def parse_specification(text):
    """Parse Specification document"""
    print("\n" + "="*60)
    print("ðŸ” PARSING SPECIFICATION")
    print("="*60)
    
    # Extract manufacturers
    manufacturers = []
    mfr_patterns = [
        r'(?i)manufacturer[s]?:\s*([^\n]+)',
        r'(?i)(?:Carlisle|GAF|Firestone|Johns Manville|Versico|Siplast|SOPREMA|Sika|Barrett|Tremco)',
    ]
    
    for pattern in mfr_patterns:
        matches = re.findall(pattern, text)
        manufacturers.extend(matches)
    
    manufacturers = deduplicate_list(manufacturers)
    print(f"  âœ“ Found {len(manufacturers)} manufacturers")
    
    # Extract products
    products = []
    product_patterns = [
        r'(?i)product[s]?:\s*([^\n]+)',
        r'(?i)[A-Z][a-z]+\s+\d+\s*mil',
    ]
    
    for pattern in product_patterns:
        matches = re.findall(pattern, text)
        products.extend(matches)
    
    products = deduplicate_list(products)
    print(f"  âœ“ Found {len(products)} products")
    
    result = {
        'manufacturers': manufacturers[:10] if manufacturers else None,
        'products': products[:15] if products else None
    }
    
    print("="*60 + "\n")
    return result

def parse_drawing_file(text, filename):
    """Parse a single architectural drawing file"""
    print("\n" + "="*60)
    print(f"ðŸ—ï¸  PARSING ARCHITECTURAL DRAWING: {filename}")
    print("="*60)
    
    try:
        # Use the enhanced parser
        parsed = parse_architectural_drawing(text)
        
        # Add filename to result
        parsed['filename'] = filename
        
        # Print summary
        if 'roof_plans' in parsed and parsed['roof_plans']:
            print(f"\n  ðŸ“Š EXTRACTION SUMMARY:")
            for i, plan in enumerate(parsed['roof_plans'], 1):
                print(f"\n  Roof Plan {i}:")
                print(f"    Sheet: {plan.get('detail_number', 'Unknown')}")
                print(f"    Type: {plan.get('type', 'Unknown')}")
                print(f"    Drains: {plan.get('drains', 'N/A')}")
                print(f"    Scuppers: {plan.get('scuppers', 'N/A')}")
                print(f"    RTUs/Curbs: {plan.get('rtus_curbs', 'N/A')}")
                print(f"    Penetrations: {plan.get('penetrations', 'N/A')}")
                print(f"    Square Footage: {plan.get('square_footage', 'N/A')}")
                print(f"    Scale: {plan.get('scale', 'N/A')}")
                
                if plan.get('legend_items'):
                    print(f"    Legend Items: {len(plan['legend_items'])} found")
        else:
            print("  âš ï¸  No roof plans detected in document")
        
        print("\n" + "="*60 + "\n")
        return parsed
        
    except Exception as e:
        print(f"  âŒ ERROR parsing drawing: {str(e)}")
        import traceback
        traceback.print_exc()
        print("="*60 + "\n")
        return {
            'error': str(e),
            'filename': filename,
            'drawing_type': 'Error',
            'roof_plans': []
        }

# ============================================================================
# ROUTES
# ============================================================================

@app.route('/')
def index():
    """Render the main page"""
    return render_template('index.html')

@app.route('/parse', methods=['POST'])
def parse_files():
    """Main parsing endpoint - handles all document types"""
    print("\n" + "ðŸš€ " + "="*58)
    print("ðŸš€  NEW PARSING REQUEST RECEIVED")
    print("ðŸš€ " + "="*58 + "\n")
    
    results = {
        'scope': None,
        'spec': None,
        'drawing': None,
        'assembly': None
    }
    
    # Process each category
    for category in ['scope', 'spec', 'drawing', 'assembly']:
        if category not in request.files:
            continue
        
        files = request.files.getlist(category)
        if not files or not files[0].filename:
            continue
        
        print(f"\nðŸ“‚ Processing {len(files)} file(s) for category: {category.upper()}")
        print("-" * 60)
        
        # Handle multiple files for drawings, assemblies, and specs
        if category in ['drawing', 'assembly', 'spec'] and len(files) > 1:
            results[category] = []

            for file in files:
                if file and file.filename:
                    # Save file
                    filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
                    file.save(filepath)
                    print(f"\n  ðŸ“¥ Saved: {file.filename}")

                    # Parse based on category
                    if category == 'drawing':
                        text = extract_text_from_pdf(filepath)
                        if not text or len(text.strip()) < 50:
                            print(f"  âš ï¸  Warning: Very little text extracted ({len(text)} chars)")
                        parsed = parse_drawing_file(text, file.filename)
                        results[category].append(parsed)

                    elif category == 'assembly':
                        text = extract_text_from_pdf(filepath)
                        if not text or len(text.strip()) < 50:
                            print(f"  âš ï¸  Warning: Very little text extracted ({len(text)} chars)")
                        parsed = parse_assembly_letter(text)
                        parsed['filename'] = file.filename
                        results[category].append(parsed)

                    elif category == 'spec':
                        parser = SpecParser(filepath)
                        parsed = parser.parse()
                        parsed['filename'] = file.filename
                        results[category].append(parsed)
        
        # Handle single file
        else:
            file = files[0]
            if file and file.filename:
                # Save file
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
                file.save(filepath)
                print(f"\n  ðŸ“¥ Saved: {file.filename}")

                # Parse based on category
                if category == 'scope':
                    results['scope'] = parse_scope(filepath)

                elif category == 'spec':
                    parser = SpecParser(filepath)
                    parsed = parser.parse()
                    parsed['filename'] = file.filename
                    results['spec'] = [parsed]  # Return as list for consistency with multiple files

                elif category == 'drawing':
                    text = extract_text_from_pdf(filepath)
                    if not text or len(text.strip()) < 50:
                        print(f"  âš ï¸  Warning: Very little text extracted ({len(text)} chars)")
                    results['drawing'] = parse_drawing_file(text, file.filename)

                elif category == 'assembly':
                    text = extract_text_from_pdf(filepath)
                    if not text or len(text.strip()) < 50:
                        print(f"  âš ï¸  Warning: Very little text extracted ({len(text)} chars)")
                    parsed = parse_assembly_letter(text)
                    parsed['filename'] = file.filename
                    results['assembly'] = parsed
    
    print("\n" + "âœ… " + "="*58)
    print("âœ…  PARSING COMPLETE - SENDING RESULTS")
    print("âœ… " + "="*58 + "\n")
    
    # Debug: Print result structure
    print("ðŸ“¤ RESULTS STRUCTURE:")
    for key, value in results.items():
        if value:
            if isinstance(value, list):
                print(f"  {key}: [{len(value)} items]")
            elif isinstance(value, dict):
                print(f"  {key}: {{...}}")
            else:
                print(f"  {key}: {type(value)}")
        else:
            print(f"  {key}: None")
    print()
    
    # Convert to JSON-safe format and return
    safe_results = safe_jsonify(results)
    return jsonify(safe_results)


# ============================================================================
# LARGE DRAWING SET PARSING
# ============================================================================

@app.route('/parse-large-drawing-set', methods=['POST'])
def parse_large_drawing_set():
    """
    Parse large architectural drawing sets (100+ pages) to find roof-related sheets.

    Two-stage approach:
    1. Python filtering - identifies roof-related pages by sheet numbers and keywords
    2. AI vision analysis (optional) - analyzes filtered pages with Claude vision

    Query params:
        - use_ai: Enable AI vision analysis (requires ANTHROPIC_API_KEY env var)
        - max_pages: Limit pages to analyze (for testing)
        - min_relevance: Minimum relevance score (0.0-1.0, default 0.3)
    """
    print("\n" + "ðŸ—ï¸ " + "="*58)
    print("ðŸ—ï¸  LARGE DRAWING SET PARSING REQUEST")
    print("ðŸ—ï¸ " + "="*58 + "\n")

    # Check for file
    if 'drawing_set' not in request.files:
        return jsonify({'error': 'No file uploaded. Use form field "drawing_set"'}), 400

    file = request.files['drawing_set']
    if not file or not file.filename:
        return jsonify({'error': 'No file selected'}), 400

    # Get options from query params
    use_ai = request.args.get('use_ai', 'false').lower() == 'true'
    max_pages = request.args.get('max_pages', type=int)
    min_relevance = request.args.get('min_relevance', 0.3, type=float)

    # Check for API key if AI requested
    api_key = os.environ.get('ANTHROPIC_API_KEY')
    if use_ai and not api_key:
        print("  âš ï¸  AI analysis requested but ANTHROPIC_API_KEY not set")
        use_ai = False

    print(f"  ðŸ“ File: {file.filename}")
    print(f"  ðŸ”§ Options: use_ai={use_ai}, max_pages={max_pages}, min_relevance={min_relevance}")

    # Save file
    filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
    file.save(filepath)
    print(f"  ðŸ“¥ Saved to: {filepath}")

    try:
        # Initialize parser
        parser = LargeDrawingSetParser(
            pdf_path=filepath,
            api_key=api_key if use_ai else None,
            min_relevance_score=min_relevance,
            use_ai_vision=use_ai
        )

        # Run parsing
        results = parser.parse(
            max_pages=max_pages,
            analyze_with_ai=use_ai
        )

        # Print summary
        summary = results.get('summary', {})
        print("\n" + "="*60)
        print("ðŸ“Š PARSING SUMMARY")
        print("="*60)
        print(f"  Total pages: {summary.get('total_pages_analyzed', 0)}")
        print(f"  Roof-related: {summary.get('roof_related_pages', 0)}")
        print(f"  Filter efficiency: {summary.get('filter_efficiency', 'N/A')}")
        print(f"  AI analyses: {summary.get('ai_analyses_completed', 0)}")
        print("="*60 + "\n")

        # Convert to JSON-safe format
        safe_results = safe_jsonify(results)
        return jsonify(safe_results)

    except Exception as e:
        print(f"  âŒ ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': str(e),
            'filename': file.filename
        }), 500


@app.route('/filter-drawing-set', methods=['POST'])
def filter_drawing_set():
    """
    Quick filter endpoint - only runs Stage 1 (Python filtering).
    Use this for fast identification of roof-related sheets without AI analysis.

    Returns list of filtered sheets with relevance scores.
    """
    print("\n" + "ðŸ” " + "="*58)
    print("ðŸ”  DRAWING SET FILTER REQUEST (Stage 1 Only)")
    print("ðŸ” " + "="*58 + "\n")

    if 'drawing_set' not in request.files:
        return jsonify({'error': 'No file uploaded. Use form field "drawing_set"'}), 400

    file = request.files['drawing_set']
    if not file or not file.filename:
        return jsonify({'error': 'No file selected'}), 400

    max_pages = request.args.get('max_pages', type=int)
    min_relevance = request.args.get('min_relevance', 0.3, type=float)

    print(f"  ðŸ“ File: {file.filename}")
    print(f"  ðŸ”§ Options: max_pages={max_pages}, min_relevance={min_relevance}")

    # Save file
    filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
    file.save(filepath)

    try:
        # Run filter only
        filter_obj = DrawingSetFilter(filepath, min_relevance)
        filtered_sheets = filter_obj.analyze_pdf(max_pages)

        # Get summary
        summary = filter_obj.get_summary()

        print(f"\n  âœ“ Found {len(filtered_sheets)} roof-related pages")
        print(f"  âœ“ Filter efficiency: {summary['filter_efficiency']}")

        return jsonify(safe_jsonify(summary))

    except Exception as e:
        print(f"  âŒ ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': str(e),
            'filename': file.filename
        }), 500


# ============================================================================
# RUN APP
# ============================================================================

if __name__ == '__main__':
    print("\n" + "ðŸ—ï¸ " + "="*58)
    print("ðŸ—ï¸  ASSEMBLY DRAWING ARCHIVE TOOL - V2")
    print("ðŸ—ï¸  Flask server starting...")
    print("ðŸ—ï¸ " + "="*58 + "\n")
    # Use PORT from environment (Railway sets this) or default to 5000
    port = int(os.environ.get('PORT', 5000))
    # host='0.0.0.0' makes it accessible on your network
    # Remove debug=True for production
    debug_mode = os.environ.get('FLASK_ENV', 'development') != 'production'
    app.run(host='0.0.0.0', debug=debug_mode, port=port)